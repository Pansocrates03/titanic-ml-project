# -*- coding: utf-8 -*-
"""Entrega2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QxBsM2LZ_2JcE_Rg-E74EZvAIudoyTlj
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
# %matplotlib inline

df = pd.read_csv("Titanic-Dataset.csv")
df.head()

df.info()

"""Modificación del dataset para facilitar su lectura"""

# Estadísticas para revisar posibles combinaciones de factores que juegan un papel clave para los datos

df['TamañoFamilia'] = df['SibSp'] + df['Parch'] + 1  # Tamaño de la familia dentro del barco
df["OrigenClase3"] = (df['Pclass'] == 3).astype(int) # Creación de variable binaria para una mejor interpretación
df["OrigenEmbarked_Southampton"] = (df['Embarked'] == 'S').astype(int)

subgrupo1 = (df["OrigenClase3"] == 1) & (df["OrigenEmbarked_Southampton"] == 1) # Creación del subgrupo que respeta las combinanciones anteriores
df['Categorias_Familia'] = pd.cut(df['TamañoFamilia'], bins=[0,1,3,6,100], labels=['1','2-3','4-6','7+']) # Categorías de familia con etiquetas
print("Total de Pasajeros de Tercera & Southampton por Familia :", df[subgrupo1].shape[0])
print("Distribución (Tercera Clase & Southampton por Tamaño de Familia):")
print(df[subgrupo1]['Categorias_Familia'].value_counts(dropna=False))

"""## Hipótesis 1: Los pasajeros con hijos menores de edad tuvieron mayor probabilidad de supervivencia que los pasajeros sin hijos menores de edad.

"""

df[subgrupo1].groupby('Categorias_Familia')['Survived'].agg(['count','mean']).rename(columns={'mean':'Supervivencia'})

import seaborn as sns
import matplotlib.pyplot as plt

# Se calcula la supervivencia por el subgrupo de categorias de tamaños de familia
survival_rate_subgrupo1 = df[subgrupo1].groupby('Categorias_Familia')['Survived'].mean().reset_index()

# Se crea un boxplot
plt.figure(figsize=(8, 5))
sns.barplot(data=survival_rate_subgrupo1, x='Categorias_Familia', y='Survived', palette='viridis')

# Add titles and labels
plt.title('Supervivencia por Categorias de Tamaños de Familia (Tercera Clase & Southampton)')
plt.xlabel('Categorias de Tamaños de Familia')
plt.ylabel('Supervivencia')

# Desplegar gráfica
plt.show()

import statsmodels.api as sm

# Variables independieentes y variable dependiente
vars_i = df[[ "TamañoFamilia", "OrigenClase3", "OrigenEmbarked_Southampton"]]
var_d = df["Survived"]

# Agregamos una constante (intercepto)
vars_i = sm.add_constant(vars_i)

# Ajustamos el modelo de regresión logística
logit_model = sm.Logit(var_d, vars_i).fit()


# Resumen de resultados
print(logit_model.summary())

"""## Hipótesis 2: a probabilidad de supervivencia en primera clase es al menos 50% mejor que la de tercera clase, para todas las edades y géneros"""

# MANTENEMOS SOLO LAS CLASES 1 Y 3 PARA EL ANÁLISIS
df_hipotesis2 = df[df['Pclass'].isin([1, 3])].copy()

media_edad = df_hipotesis2['Age'].mean()
df_hipotesis2['Age'] = df_hipotesis2['Age'].fillna(media_edad)

# --- 1. ANÁLISIS VISUAL PARA SUBGRUPOS (GÉNERO Y CLASE) ---

# CALCULAMOS LA TASA DE SUPERVIVENCIA POR GÉNERO Y CLASE
survival_rate_gender_class = df_hipotesis2.groupby(['Sex', 'Pclass'])['Survived'].mean().reset_index()

# CREAMOS UNA GRÁFICA DE BARRAS
plt.figure(figsize=(10, 6))
sns.barplot(
    data=survival_rate_gender_class,
    x='Sex',
    y='Survived',
    hue='Pclass',
    palette='pastel'
)

plt.title('SUPERVIVENCIA POR CLASE Y GÉNERO')
plt.xlabel('GÉNERO')
plt.ylabel('TASA DE SUPERVIVENCIA')
plt.legend(title='CLASE', loc='upper right')
plt.show()

# --- 2. MODELO DE REGRESIÓN LOGÍSTICA PARA EL ANÁLISIS PRINCIPAL ---

# VARIABLE DEPENDIENTE: Supervivencia
var_d = df_hipotesis2["Survived"]

# VARIABLES INDEPENDIENTES: Pclass, Sex y Age
# PCLASS: CONVERTIMOS LA CLASE 1 EN DUMMY (1 SI ES CLASE 1, 0 SI ES CLASE 3)
df_hipotesis2['Pclass_1'] = np.where(df_hipotesis2['Pclass'] == 1, 1, 0)

# SEX: CONVERTIMOS EL GÉNERO EN DUMMY (1 SI ES HOMBRE, 0 SI ES MUJER)
df_hipotesis2['Sex_male'] = np.where(df_hipotesis2['Sex'] == 'male', 1, 0)

# SELECCIONAMOS LAS VARIABLES PARA EL MODELO
vars_i = df_hipotesis2[['Pclass_1', 'Sex_male', 'Age']]

# AGREGAMOS UNA CONSTANTE (INTERCEPTO)
vars_i = sm.add_constant(vars_i)

# AJUSTAMOS EL MODELO DE REGRESIÓN LOGÍSTICA
logit_model = sm.Logit(var_d, vars_i).fit()

print("\n--- RESUMEN DE LA REGRESIÓN LOGÍSTICA ---")
print(logit_model.summary())

# --- 3. EVALUACIÓN DE LA HIPÓTESIS ---

print("\n--- CRITERIOS DE DECISIÓN (ANÁLISIS PRINCIPAL) ---")
# OBTENEMOS EL ODDS RATIO PARA LA VARIABLE 'Pclass_1'
odds_ratio_pclass = np.exp(logit_model.params['Pclass_1'])
p_value_pclass = logit_model.pvalues['Pclass_1']

print(f"VALOR P PARA PCLASS_1: {p_value_pclass:.4f}")
print(f"ODDS RATIO PARA PCLASS_1: {odds_ratio_pclass:.2f}")

# VERIFICAMOS LA SIGNIFICANCIA ESTADÍSTICA Y EL TAMAÑO DEL EFECTO
if p_value_pclass < 0.05:
    print("LA VARIABLE 'PCLASS' ES ESTADÍSTICAMENTE SIGNIFICATIVA.")
    if odds_ratio_pclass >= 1.5:
        print("EL ODDS RATIO ES MAYOR O IGUAL A 1.5.")
        print("ESTE ANÁLISIS APOYA LA HIPÓTESIS PRINCIPAL.")
    else:
        print("EL ODDS RATIO ES MENOR A 1.5.")
        print("LA HIPÓTESIS NO SE CUMPLE CON EL TAMAÑO DE EFECTO MÍNIMO REQUERIDO.")
else:
    print("LA VARIABLE 'PCLASS' NO ES ESTADÍSTICAMENTE SIGNIFICATIVA.")
    print("NO HAY EVIDENCIA PARA APOYAR LA HIPÓTESIS PRINCIPAL.")

# --- 4. ANÁLISIS DE SUBGRUPOS (REGRESIÓN LOGÍSTICA POR GÉNERO) ---

# SUBGRUPO: MUJERES
print("\n--- SUBGRUPO: MUJERES ---")
df_mujeres = df_hipotesis2[df_hipotesis2['Sex_male'] == 0].copy()
if not df_mujeres.empty:
    vars_i_mujeres = df_mujeres[['Pclass_1', 'Age']]
    var_d_mujeres = df_mujeres['Survived']
    vars_i_mujeres = sm.add_constant(vars_i_mujeres)
    try:
        modelo_mujeres = sm.Logit(var_d_mujeres, vars_i_mujeres).fit()
        odds_ratio_mujeres = np.exp(modelo_mujeres.params['Pclass_1'])
        p_value_mujeres = modelo_mujeres.pvalues['Pclass_1']

        print(f"ODDS RATIO PARA MUJERES: {odds_ratio_mujeres:.2f}")
        print(f"VALOR P PARA MUJERES: {p_value_mujeres:.4f}")

        if p_value_mujeres < 0.05 and odds_ratio_mujeres >= 1.5:
            print("LA HIPÓTESIS SE CUMPLE EN EL SUBGRUPO DE MUJERES.")
        else:
            print("LA HIPÓTESIS NO SE CUMPLE EN EL SUBGRUPO DE MUJERES.")
    except Exception as e:
        print(f"ERROR AL AJUSTAR EL MODELO PARA MUJERES: {e}")
else:
    print("NO HAY DATOS EN EL SUBGRUPO DE MUJERES.")


# SUBGRUPO: HOMBRES
print("\n--- SUBGRUPO: HOMBRES ---")
df_hombres = df_hipotesis2[df_hipotesis2['Sex_male'] == 1].copy()
if not df_hombres.empty:
    vars_i_hombres = df_hombres[['Pclass_1', 'Age']]
    var_d_hombres = df_hombres['Survived']
    vars_i_hombres = sm.add_constant(vars_i_hombres)
    try:
        modelo_hombres = sm.Logit(var_d_hombres, vars_i_hombres).fit()
        odds_ratio_hombres = np.exp(modelo_hombres.params['Pclass_1'])
        p_value_hombres = modelo_hombres.pvalues['Pclass_1']

        print(f"ODDS RATIO PARA HOMBRES: {odds_ratio_hombres:.2f}")
        print(f"VALOR P PARA HOMBRES: {p_value_hombres:.4f}")

        if p_value_hombres < 0.05 and odds_ratio_hombres >= 1.5:
            print("LA HIPÓTESIS SE CUMPLE EN EL SUBGRUPO DE HOMBRES.")
        else:
            print("LA HIPÓTESIS NO SE CUMPLE EN EL SUBGRUPO DE HOMBRES.")
    except Exception as e:
        print(f"ERROR AL AJUSTAR EL MODELO PARA HOMBRES: {e}")
else:
    print("NO HAY DATOS EN EL SUBGRUPO DE HOMBRES.")



"""## Hipótesis 3: La posibilidad de supervivencia disminuye en cuestión de ser de tercera vinculados a varios familiares provenientes de Southampton

"""

# SECCIÓN DEL CÓDIGO PARA VALIDAR LA HIPÓTESIS 3
# HIPÓTESIS: LA POSIBILIDAD DE SUPERVIVENCIA DISMINUYE EN CUESTIÓN DE SER DE TERCERA,
# VINCULADOS A VARIOS FAMILIARES PROVENIENTES DE SOUTHAMPTON

import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns

# --- 1. CARGAR DATASET Y PREPROCESAMIENTO ---
print("--- preprocesamiento de datos para la hipótesis 3 ---")
try:
    df = pd.read_csv("Titanic-Dataset.csv")
    print("dataset 'titanic-dataset.csv' cargado correctamente.")
except filenotfounderror:
    print("error: el archivo 'titanic-dataset.csv' no fue encontrado.")
    print("asegúrate de que el archivo esté en la misma carpeta que el script.")

df.columns = df.columns.str.lower()

df['age'] = df['age'].fillna(df['age'].median())
df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])
df['fare'] = df['fare'].fillna(df['fare'].mean())

# crear la variable 'familysize' (tamaño de la familia)
df['familysize'] = df['sibsp'] + df['parch'] + 1
df['embarked'] = df['embarked'].str.strip()
df['sex_male'] = (df['sex'] == 'male').astype(int)
df['embarked_s'] = (df['embarked'] == 's').astype(int)
df['pclass_3'] = (df['pclass'] == 3).astype(int)


# --- 2. creación de la variable de interacción (analisis principal) ---
print("\n--- creando variable de interacción para el análisis principal ---")
df['hipotesis3_interaction'] = np.where(
    (df['pclass_3'] == 1) & (df['familysize'] > 1) & (df['embarked_s'] == 1),
    1,
    0
)

# --- 3. análisis visual de la interacción ---
print("\n--- visualización de la tasa de supervivencia del grupo de hipótesis ---")
survival_rate_grupo = df.groupby('hipotesis3_interaction')['survived'].mean().reset_index()

plt.figure(figsize=(8, 6))
sns.barplot(
    data=survival_rate_grupo,
    x='hipotesis3_interaction',
    y='survived',
    palette='viridis'
)
plt.title('tasa de supervivencia: grupo de hipótesis vs. resto')
plt.xlabel('grupo de hipótesis (1=sí, 0=no)')
plt.ylabel('tasa de supervivencia')
plt.xticks(ticks=[0, 1], labels=['otros pasajeros', 'grupo de hipótesis'])
plt.show()

# --- 4. modelo de regresión logística para el análisis principal ---
print("\n" + "="*50)
print("--- ajuste del modelo de regresión logística ---")
print("="*50)

# seleccionar variables independientes y dependientes
vars_i = df[['hipotesis3_interaction', 'age', 'sex_male']]
var_d = df['survived']
vars_i = sm.add_constant(vars_i)

try:

    modelo = sm.Logit(var_d, vars_i).fit()
    print(modelo.summary())

    # --- 5. interpretación de resultados ---
    print("\n" + "="*50)
    print("--- evaluación de la hipótesis ---")
    print("="*50)

    odds_ratio = np.exp(modelo.params['hipotesis3_interaction'])
    p_value = modelo.pvalues['hipotesis3_interaction']

    print(f"odds ratio para la interacción de la hipótesis 3: {odds_ratio:.4f}")
    print(f"valor p para la interacción de la hipótesis 3: {p_value:.4f}")

    if p_value < 0.05 and odds_ratio < 1.0:
        print("\nconclusión: la hipótesis es estadísticamente significativa y es apoyada por los datos.")
        print("la posibilidad de supervivencia disminuye para este grupo específico.")
    else:
        print("\nconclusión: la hipótesis no es estadísticamente significativa o no se cumple.")
        print("el valor p es mayor a 0.05 o el odds ratio es mayor a 1.")

except Exception as e:
    print(f"\nerror al ajustar el modelo: {e}")







"""# **INGENIERIA DE FEATURES**

# 2.1 Creación de Variables Derivadas
"""

# --- 1. VARIABLE: Title (TITULO) ---

def title_feature(df):
    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')
    df['Title'] = df['Title'].replace('Mlle', 'Miss')
    df['Title'] = df['Title'].replace('Ms', 'Miss')
    df['Title'] = df['Title'].replace('Mme', 'Mrs')
    # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
    print("RELACIÓN DE 'Title' CON LA SUPERVIVENCIA:")
    print(df.groupby('Title')['Survived'].mean().sort_values(ascending=False))
    # VERIFICACIÓN DE CALIDAD
    print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
    print(df['Title'].value_counts())

title_feature(df)

# --- 2. VARIABLE: FamilySize (TAMAÑO DE LA FAMILIA) ---

def family_size_feature(df):
    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
    # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
    print("RELACIÓN DE 'FamilySize' CON LA SUPERVIVENCIA:")
    print(df.groupby('FamilySize')['Survived'].mean())
    # VERIFICACIÓN DE CALIDAD
    print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
    print(df['FamilySize'].value_counts().sort_index())

family_size_feature(df)

# --- 3. VARIABLE: IsAlone (ESTA SOLO) ---

def is_alone_feature(df):
    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)
    # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
    print("RELACIÓN DE 'IsAlone' CON LA SUPERVIVENCIA:")
    print(df.groupby('IsAlone')['Survived'].mean())
    # VERIFICACIÓN DE CALIDAD
    print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
    print(df['IsAlone'].value_counts())

is_alone_feature(df)

# --- 4. VARIABLE: AgeGroup (GRUPO DE EDAD) ---
# MANEJO DE VALORES NULOS PARA LA EDAD

def age_group_feature(df):
      df['Age'].fillna(df['Age'].median(), inplace=True)
      bins = [0, 12, 18, 60, np.inf]
      labels = ['Child', 'Adolescent/Teenager', 'Adult', 'Senior']
      df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)
      # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
      print("RELACIÓN DE 'AgeGroup' CON LA SUPERVIVENCIA:")
      print(df.groupby('AgeGroup')['Survived'].mean().sort_values(ascending=False))
      # VERIFICACIÓN DE CALIDAD
      print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
      print(df['AgeGroup'].value_counts())

age_group_feature(df)

# --- 5. VARIABLE: FarePerPerson (TARIFA POR PERSONA) ---

def fare_per_person_feature(df):
    df['FarePerPerson'] = df['Fare'] / df['FamilySize']
    df['FarePerPerson'].fillna(df['FarePerPerson'].mean(), inplace=True) # Manejo de Nulos
    # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA (AGRUPANDO EN RANGOS)
    print("RELACIÓN DE 'FarePerPerson' CON LA SUPERVIVENCIA (POR RANGOS):")
    df['FarePerPerson_Group'] = pd.qcut(df['FarePerPerson'], 4, labels=['Q1', 'Q2', 'Q3', 'Q4'])
    print(df.groupby('FarePerPerson_Group')['Survived'].mean().sort_values(ascending=False))
    # VERIFICACIÓN DE CALIDAD
    print("\nVERIFICACIÓN DE LA DISTRIBUCIÓN:")
    print(df['FarePerPerson'].describe())

fare_per_person_feature(df)

# --- 6. VARIABLE: CabinDeck (CUBIERTA DE LA CABINA) ---

def cabin_deck_feature(df):
    df['CabinDeck'] = df['Cabin'].str.extract('([A-Z])', expand=False)
    df['CabinDeck'].fillna('Unknown', inplace=True)
    # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
    print("RELACIÓN DE 'CabinDeck' CON LA SUPERVIVENCIA:")
    print(df.groupby('CabinDeck')['Survived'].mean().sort_values(ascending=False))
    # VERIFICACIÓN DE CALIDAD
    print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
    print(df['CabinDeck'].value_counts())

cabin_deck_feature(df)

# --- 7. VARIABLE: CabinKnown (CABINA CONOCIDA) ---

def cabin_known_feature(df):
  df['CabinKnown'] = df['Cabin'].isnull().astype(int)
  # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
  print("RELACIÓN DE 'CabinKnown' CON LA SUPERVIVENCIA:")
  print(df.groupby('CabinKnown')['Survived'].mean())
  # VERIFICACIÓN DE CALIDAD
  print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
  print(df['CabinKnown'].value_counts())

cabin_known_feature(df)

# --- 8. VARIABLE: TicketFrequency (FREQUENCIA DE TICKEY ) ---

def ticket_frequency_feature(df):
  df['TicketFrequency'] = df.groupby('Ticket')['Ticket'].transform('count')
  # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
  print("RELACIÓN DE 'TicketFrequency' CON LA SUPERVIVENCIA:")
  print(df.groupby('TicketFrequency')['Survived'].mean())
  # VERIFICACIÓN DE CALIDAD
  print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
  print(df['TicketFrequency'].value_counts().sort_index())

ticket_frequency_feature(df)

# --- 9. VARIABLE: NameLength (LONGITUD DE NOMBRE ) ---

def name_length_feature(df):
  df['NameLength'] = df['Name'].str.len()
  # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
  print("RELACIÓN DE 'NameLength' CON LA SUPERVIVENCIA:")
  print(df.groupby('NameLength')['Survived'].mean())
  # VERIFICACIÓN DE CALIDAD
  print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
  print(df['NameLength'].value_counts().sort_index())

name_length_feature(df)

# --- 10. VARIABLE: HasCabinNeighbor (CABINAS CERCANAS CON FAMILIARES ) ---

def has_cabin_neighbor_feature(df):
    df['HasCabinNeighbor'] = df['Cabin'].notnull().astype(int)
    # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
    print("RELACIÓN DE 'HasCabinNeighbor' CON LA SUPERVIVENCIA:")
    print(df.groupby('HasCabinNeighbor')['Survived'].mean())
    # VERIFICACIÓN DE CALIDAD
    print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
    print(df['HasCabinNeighbor'].value_counts())

has_cabin_neighbor_feature(df)

# --- 11. VARIABLE: TicketPrefix (PREFIJO DEL TCIKET ) ---

def ticket_prefix_feature(df):
    df['TicketPrefix'] = df['Ticket'].str.extract(r'([A-Za-z]+)\d*')
    df['TicketPrefix'].fillna('Unknown', inplace=True)
    # ANÁLISIS DE LA RELACIÓN CON SUPERVIVENCIA
    print("RELACIÓN DE 'TicketPrefix' CON LA SUPERVIVENCIA:")
    print(df.groupby('TicketPrefix')['Survived'].mean().sort_values(ascending=False))
    # VERIFICACIÓN DE CALIDAD
    print("\nVERIFICACIÓN DE VALORES ÚNICOS Y CONTEO:")
    print(df['TicketPrefix'].value_counts())

ticket_prefix_feature(df)

"""# 2.2 Transformaciones de Variables Existentes"""

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Estructura mínima requerida:
class TitanicDatasetPreprocessor:
    def __init__(self, imputation_strategy='knn'):
        self.imputation_strategy = imputation_strategy
        self.encoders = {}
        self.scalers = {}

    def fit(self, X, y=None):
        # Aprender parámetros de transformación
        return self

    def transform(self, X):
        # Aplicar transformaciones
        return X_transformed

    def fit_transform(self, X, y=None):
        return self.fit(X, y).transform(X)

"""## Consideraciones de Sesgo y Ética

1. Sesgo de supervivencia
"""

# Calcular el porcentaje de valores faltantes por columna para supervivientes y no supervivientes
missing_survived = df[df['Survived'] == 1].isnull().sum() / len(df[df['Survived'] == 1]) * 100
missing_not_survived = df[df['Survived'] == 0].isnull().sum() / len(df[df['Survived'] == 0]) * 100

# Crear un DataFrame para facilitar la visualización
missing_data = pd.DataFrame({'Survived': missing_survived, 'Not Survived': missing_not_survived})

# Eliminar filas donde no hay valores faltantes en ninguna de las categorías
missing_data = missing_data[(missing_data['Survived'] > 0) | (missing_data['Not Survived'] > 0)]

# Graficar
plt.figure(figsize=(12, 6))
missing_data.plot(kind='bar', figsize=(12, 6))
plt.title('Porcentaje de Valores Faltantes por Columna (Supervivientes vs. No Supervivientes)')
plt.xlabel('Columnas')
plt.ylabel('Porcentaje de Valores Faltantes (%)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Estrategia de mitigación sobre el sesgo de supervivencia: Análisis de sensibilidad"""

# Análisis de Sensibilidad para Mitigar el Sesgo de Supervivencia
# Estrategia: Imputar valores faltantes bajo diferentes supuestos y observar cómo afecta a los resultados clave.

# 1. Imputación Pessimista: Asumir que todos los pasajeros con cabina desconocida (NaN) NO sobrevivieron.
df_pessimist = df.copy()
df_pessimist['Cabin'].fillna('Unknown', inplace=True)
# Creamos una columna binaria para indicar si la cabina era desconocida
df_pessimist['CabinUnknown'] = (df_pessimist['Cabin'] == 'Unknown').astype(int)
# Asignamos 0 a 'Survived' para los que tenían 'CabinUnknown' (solo si 'Survived' no es nulo originalmente)
df_pessimist.loc[df_pessimist['CabinUnknown'] == 1, 'Survived_Pessimist'] = 0
# Para el resto, usamos el valor original de 'Survived'
df_pessimist.loc[df_pessimist['CabinUnknown'] == 0, 'Survived_Pessimist'] = df_pessimist['Survived']

print("\n--- Análisis de Sensibilidad (Imputación Pessimista) ---")
print("Tasa de supervivencia con imputación pesimista:", df_pessimist['Survived_Pessimist'].mean())

# 2. Imputación Optimista: Asumir que todos los pasajeros con cabina desconocida (NaN) SÍ sobrevivieron.
df_optimist = df.copy()
df_optimist['Cabin'].fillna('Unknown', inplace=True)
df_optimist['CabinUnknown'] = (df_optimist['Cabin'] == 'Unknown').astype(int)
# Asignamos 1 a 'Survived' para los que tenían 'CabinUnknown'
df_optimist.loc[df_optimist['CabinUnknown'] == 1, 'Survived_Optimist'] = 1
# Para el resto, usamos el valor original de 'Survived'
df_optimist.loc[df_optimist['CabinUnknown'] == 0, 'Survived_Optimist'] = df_optimist['Survived']

print("\n--- Análisis de Sensibilidad (Imputación Optimista) ---")
print("Tasa de supervivencia con imputación optimista:", df_optimist['Survived_Optimist'].mean())

# 3. Comparación con la tasa de supervivencia original
print("\n--- Comparación ---")
print("Tasa de supervivencia original:", df['Survived'].mean())

# Interpretación: La diferencia en las tasas de supervivencia bajo los escenarios optimista y pesimista
# indica la sensibilidad de los resultados a la forma en que se tratan los valores faltantes en la cabina.
# Si la diferencia es grande, el sesgo por datos faltantes en la cabina es significativo.

# Calcular el porcentaje de valores faltantes por columna para cada clase social
missing_pclass1 = df[df['Pclass'] == 1].isnull().sum() / len(df[df['Pclass'] == 1]) * 100
missing_pclass2 = df[df['Pclass'] == 2].isnull().sum() / len(df[df['Pclass'] == 2]) * 100
missing_pclass3 = df[df['Pclass'] == 3].isnull().sum() / len(df[df['Pclass'] == 3]) * 100


# Crear un DataFrame para facilitar la visualización
missing_data_pclass = pd.DataFrame({'Pclass 1': missing_pclass1, 'Pclass 2': missing_pclass2, 'Pclass 3': missing_pclass3})

# Eliminar filas donde no hay valores faltantes en ninguna de las categorías
missing_data_pclass = missing_data_pclass[(missing_data_pclass['Pclass 1'] > 0) | (missing_data_pclass['Pclass 2'] > 0) | (missing_data_pclass['Pclass 3'] > 0)]

# Graficar
plt.figure(figsize=(12, 6))
missing_data_pclass.plot(kind='bar', figsize=(12, 6))
plt.title('Porcentaje de Valores Faltantes por Columna (Por Clase Social)')
plt.xlabel('Columnas')
plt.ylabel('Porcentaje de Valores Faltantes (%)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Calcular el porcentaje de valores faltantes por columna por género
missing_men = df[df['Sex'] == 'male'].isnull().sum() / len(df[df['Sex'] == 'male']) * 100
missing_women = df[df['Sex'] == 'female'].isnull().sum() / len(df[df['Sex'] == 'female']) * 100


# Crear un DataFrame para facilitar la visualización
missing_data_gender = pd.DataFrame({'Men': missing_men, 'Women': missing_women})

# Eliminar filas donde no hay valores faltantes en ninguna de las categorías
missing_data_gender = missing_data_gender[(missing_data_gender['Men'] > 0) | (missing_data_gender['Women'] > 0)]

# Graficar
plt.figure(figsize=(12, 6))
missing_data_gender.plot(kind='bar', figsize=(12, 6))
plt.title('Porcentaje de Valores Faltantes por Columna (Por sexo)')
plt.xlabel('Columnas')
plt.ylabel('Porcentaje de Valores Faltantes (%)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()



"""## 2. Sesgo Histórico y Grupos Subrepresentados

Es crucial considerar si existen sesgos históricos inherentes al evento del Titanic que puedan verse reflejados en el dataset, lo que podría llevar a la subrepresentación de ciertos grupos entre los supervivientes o incluso en los datos disponibles.

**Posibles áreas de Sesgo Histórico:**

*   **Clase Social:** Históricamente, los pasajeros de clases más bajas a menudo tuvieron menos acceso a botes salvavidas y peores condiciones de viaje. Esto podría significar una subrepresentación de las clases bajas entre los supervivientes.
*   **Género:** Las políticas de "mujeres y niños primero" influyeron significativamente en las tasas de supervivencia, lo que resultó en una mayor proporción de mujeres y niños entre los supervivientes en comparación con los hombres adultos.
*   **Edad:** Similar al género, los niños fueron priorizados, lo que podría llevar a una subrepresentación de adultos jóvenes y de mediana edad entre los supervivientes.
*   **Origen/Puerto de Embarque:** Las condiciones y la organización del embarque en los diferentes puertos (Southampton, Cherbourg, Queenstown) podrían haber afectado a diferentes grupos de pasajeros de manera desigual.

**Análisis en el Dataset:**

Para investigar esto en nuestro dataset, podemos analizar la distribución de los pasajeros por clase social, género y edad, y comparar estas distribuciones con las tasas de supervivencia.

**Próximos Pasos para Identificar Sesgo:**

Podemos generar visualizaciones y estadísticas para explorar la composición del dataset en términos de estas características demográficas y observar cómo se distribuye la supervivencia dentro de estos grupos. Por ejemplo:

*   Gráficos de barras que muestren el número de pasajeros por clase, género y grupo de edad.
*   Comparación de las tasas de supervivencia por clase, género y grupo de edad.
*   Análisis combinado de factores, como la supervivencia por género dentro de cada clase.

Este análisis nos ayudará a identificar qué grupos podrían haber estado en desventaja histórica y si esa desventaja se refleja en su representación en el conjunto de datos de supervivientes.

# Tratamiento de datos faltantes

WIP local de Omar

# Tratamiento de datos faltantes

Hay solamente 3 columnas con valores faltantes en el dataset:



1.   Edad (`Age`)
2.   Cabina (`Cabin`)
3.   Puerto de embarcación (`Cabin`)
"""

df = pd.read_csv("Titanic-Dataset.csv") # vuelvo a cargar los datos, porque fueron rellenados en analisis anteriores.
df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
df['Fare_bin'] = pd.qcut(df['Fare'], 4, labels=["Q1","Q2","Q3","Q4"])

# Crear indicadores de valores faltantes
df['Age_missing'] = df['Age'].isnull().astype(int)
df['Cabin_missing'] = df['Cabin'].isnull().astype(int)
df['Embarked_missing'] = df['Embarked'].isnull().astype(int)

df.columns[df.isna().any()]

"""## Missingness de puerto de embarcación (`Embarked`)

Embarked es la unica columna en la que menos de 10 valores falta. En total, solo faltan 2 valores, ambos en primera clase:
"""

df[df['Embarked'].isnull() == True]

"""Las dos mujeres sin la indicación del puerto en el que subieron comparten el mismo numero de ticket (en primera clase), ambas sobrevivieron, y estaban en la misma cabina.

Es difícil decir si hay relación entre el valor faltante y las demás variables, pues más allá de estas coincidencias parece que no había un parentezco o relación entre ellas.
*   No comparten apellidos
*   No indican tener parientes abordo

Son las unicas dos personas en la cabina B28, así que nuestra mejor teoría es que no se registró

Para esta variable concluimos que es **completamente aleatoria**, pero por el tamaño de muestra tan pequeño, es practicamente imposible hacer un análisis estadístico más profundo con significancia.

#### Imputación

Al ser una muestra tan pequeña, usar la moda entre los pasajeros de primera clase, Southampton, es razonable, y no debería de lastimar ningún análisis que asuma así el dato. Dicho eso, solamente 2 pasajeros no tienen este dato, puede que sea mejor simplemente eliminarlos de la muestra cuando sea de importancia el puerto.

## Missingness de Cabin

### Patrón de missingess

La falta de los valores de Cabin es bastante notorio, e incluso al primer vistazo es aparente que no es **completamente** aleatorio, sino que está fuertemente correlacionado a la clase de boleto y su costo, pero sin ser basado en el valor mismo de la columna. **(MAR)**

### Evidencia Estadística

Hay multiples correlaciones que se exploraron para llegar a esta conclusión, empezando por la evidente correlación a la clase de boleto, seguido de la supervivencia, la tarifa pagada, y el tamaño de la familia.
"""

df['Cabin_missing'] = df['Cabin'].isnull().astype(int)

pivot_cabin_class = df.groupby("Pclass")["Cabin_missing"].mean() * 100
pivot_cabin_surv = df.groupby("Survived")["Cabin_missing"].mean() * 100
pivot_cabin_fare = df.groupby("Fare_bin")["Cabin_missing"].mean() * 100
pivot_cabin_family = df.groupby("FamilySize")["Cabin_missing"].mean() * 100

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Por Clase
pivot_cabin_class.plot(kind="bar", color="steelblue", ax=axes[0,0])
axes[0,0].set_title("Porcentaje de Cabina Faltantes por Clase")
axes[0,0].set_ylabel("% Faltante")
axes[0,0].set_xlabel("Clase (Pclass)")

# Por Supervivencia
pivot_cabin_surv.plot(kind="bar", color="orange", ax=axes[0,1])
axes[0,1].set_title("Porcentaje de Cabina Faltantes por Supervivencia")
axes[0,1].set_ylabel("% Faltante")
axes[0,1].set_xlabel("Supervivencia (0=No, 1=Sí)")

# Por Cuartiles de Tarifa
pivot_cabin_fare.plot(kind="bar", color="green", ax=axes[1,0])
axes[1,0].set_title("Porcentaje de Cabina Faltantes por Cuartiles de Tarifa")
axes[1,0].set_ylabel("% Faltante")
axes[1,0].set_xlabel("Cuartil de Tarifa")

# Por Tamaño de Familia
pivot_cabin_family.plot(kind="bar", color="purple", ax=axes[1,1])
axes[1,1].set_title("Porcentaje de Cabina Faltantes por Tamaño de Familia")
axes[1,1].set_ylabel("% Faltante")
axes[1,1].set_xlabel("Tamaño de Familia")

plt.tight_layout()
plt.show()

"""Observando el porcentaje de cada clase que no tiene registrada la cabina, es claro que en general no era una prioridad mantener el registro de las cabinas de los pasajeros, pues incluso en primera clase (`Pclass == 1`), 18.5% de los pasajeros no tenian registrada la cabina en la que se hospedaban. Dicho esto, esa es la mayor correlación que se presenta en el dataset."""

pivot_cabin_class

"""La otra variable que parece tener una tendencia es la del tamaño de familia. En este caso, ninguna de las familias grandes a bordo del Titanic tenían registrada una cabina.
Entre esas familias grandes estan algunas como:

* Familia Sage (11 personas)
* Familia Goodwin (8 personas)
* Familia Andersson (7 personas)
* Familia Asplund (7 personas)
* Familia Rice (6 personas)
* Familia Panula (6 personas)

Todas estas familias viajaban en tercera clase, lo que nos regresa a nuestra más grande correlación, que puede que haya sido exacerbada por el tamaño de la familia, y la logística de acomodarlos a todos dentro del barco.

### Casos completos vs. incompletos

La clase de boleto hace la diferencia más marcada, y apunta a un elemento sistemático en la falta de registro de las cabinas. Pero es necesario hacer un anális estadístico que lo demuestre.
"""

# tabla de contingencia
contingency = pd.crosstab(df['Pclass'], df['Cabin_missing'])

# Chi cuadrado
chi2, p, dof, expected = stats.chi2_contingency(contingency)

print("Chi-cuadrado para Cabin_missing vs Pclass")
print("Chi2 =", chi2, "p-value =", p)

"""El valor de *p* es tan bajo que es indudable que la diferencia es significativa.

Algunas de las variables parecen indicar correlación también, como la tarifa o la supervivencia, pero solo son un reflejo de la correlación por clase.
"""

survival_all = df['Survived'].value_counts(normalize=True) * 100
survival_missing = df.loc[df['Cabin_missing']==1, 'Survived'].value_counts(normalize=True) * 100

fare_all = df['Fare'].dropna()
fare_missing = df.loc[df['Cabin_missing']==1, 'Fare'].dropna()

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Gráfico 1: Supervivencia (todos los pasajeros)
survival_all.plot(kind="bar", color="steelblue", ax=axes[0,0])
axes[0,0].set_title("Distribución de Supervivencia (Todos los Pasajeros)")
axes[0,0].set_ylabel("% de Pasajeros")
axes[0,0].set_xlabel("Supervivencia (0=No, 1=Sí)")
axes[0,0].set_ylim(0, 100)

# Gráfico 2: Supervivencia (solo Cabin faltante)
survival_missing.plot(kind="bar", color="orange", ax=axes[0,1])
axes[0,1].set_title("Distribución de Supervivencia (Solo Cabin Faltante)")
axes[0,1].set_ylabel("% de Pasajeros")
axes[0,1].set_xlabel("Supervivencia (0=No, 1=Sí)")
axes[0,1].set_ylim(0, 100)

# Gráfico 3: Histograma de Tarifa (todos los pasajeros)
axes[1,0].hist(fare_all, bins=10, color="green", alpha=0.7)
axes[1,0].set_title("Distribución de Tarifa (Todos los Pasajeros)")
axes[1,0].set_xlabel("Tarifa")
axes[1,0].set_ylabel("Frecuencia")
axes[1,0].set_ylim(0, 700)

# Gráfico 4: Histograma de Tarifa (solo Cabin faltante)
axes[1,1].hist(fare_missing, bins=10, color="purple", alpha=0.7)
axes[1,1].set_title("Distribución de Tarifa (Solo Cabin Faltante)")
axes[1,1].set_xlabel("Tarifa")
axes[1,1].set_ylabel("Frecuencia")
axes[1,1].set_ylim(0, 700)

plt.tight_layout()
plt.show()

# tabla de contingencia
contingency = pd.crosstab(df['Pclass'], df['Cabin_missing'])

# Chi cuadrado
chi2, p, dof, expected = stats.chi2_contingency(contingency)

print("Chi-cuadrado para Cabin_missing vs Pclass")
print("Chi2 =", chi2, "p-value =", p)

"""### Correlación

La matriz de correlación deja esto aún más claro. La mayor correlación con la falta del registro de la cabina se encuentra con la clase del boleto, y ninguna otra correlación moderadamente fuerte se encuentra, más allá de la de la tarifa. Sin embargo, en la exploración inicial del dataset ya se sabía que la tarifa y la clase del boleto van mano en mano.
"""

# variables para la matriz de correlación
corr_vars = [
    'Cabin_missing', 'Pclass', 'Fare', 'Survived', 'FamilySize',
    'Age_missing', 'Embarked_missing'
]

# Calcular matriz de correlación
metodo = 'Pearson' # Parece que Pearson es apropiado para este caso, pero los demas mostraban resultados similares
corr_matrix = df[corr_vars].corr(method=metodo.lower())

# Graficar heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", center=0, fmt=".2f")
plt.title(f"Matriz de Correlación ({metodo}) entre variables y valores Faltantes")
plt.show()

"""## Missingess de Age

### Patrón de missingness
Comparado a la cabina, el registro de la edad es mucho mas extenso, aunque sigue presentando una tendencia a que aquellos en tercera clase eran menos propensos a registrarse.
"""

pivot_age = pd.pivot_table(df, values="Age_missing", index="Pclass", aggfunc=["mean", "sum"])
pivot_age

pivot_age_class = df.groupby("Pclass")["Age_missing"].mean() * 100
pivot_age_surv = df.groupby("Survived")["Age_missing"].mean() * 100
pivot_age_fare = df.groupby("Fare_bin")["Age_missing"].mean() * 100
pivot_age_family = df.groupby("FamilySize")["Age_missing"].mean() * 100

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Por Clase
pivot_age_class.plot(kind="bar", color="steelblue", ax=axes[0,0])
axes[0,0].set_title("Porcentaje de Edad faltante por Clase")
axes[0,0].set_ylabel("% Faltante")
axes[0,0].set_xlabel("Clase (Pclass)")

# Por Supervivencia
pivot_age_surv.plot(kind="bar", color="orange", ax=axes[0,1])
axes[0,1].set_title("Porcentaje de Edad faltante por Supervivencia")
axes[0,1].set_ylabel("% Faltante")
axes[0,1].set_xlabel("Supervivencia (0=No, 1=Sí)")

# Por Cuartiles de Tarifa
pivot_age_fare.plot(kind="bar", color="green", ax=axes[1,0])
axes[1,0].set_title("Porcentaje de Edad faltante por Cuartiles de Tarifa")
axes[1,0].set_ylabel("% Faltante")
axes[1,0].set_xlabel("Cuartil de Tarifa")

# Por Tamaño de Familia
pivot_age_family.plot(kind="bar", color="purple", ax=axes[1,1])
axes[1,1].set_title("Porcentaje de Edad faltante por Tamaño de Familia")
axes[1,1].set_ylabel("% Faltante")
axes[1,1].set_xlabel("Tamaño de Familia")

plt.tight_layout()
plt.show()

"""Una vez más el tamaño de familia se puede considerar un outlier, siendo que la familia Sage tampoco registró la edad de ninguno de los miembros de la familia. Dicho eso, es sorprendente que las otras grandes familias como la Andersson o Asplund registraron la edad de todos los miembros, desde los bebés de 1 o 2 años hasta las cabezas de la familia.

Aunque la relación no es tan clara como en el caso de las cabinas, se sigue pudiendo demostrar que el registro de la edad está relacionado a clase, como lo demuestra esta prueba de Chi cuadrado:
"""

contingency = pd.crosstab(df['Pclass'], df['Age_missing'])

chi2, p, dof, expected = stats.chi2_contingency(contingency)

print("Chi-cuadrado para Age_missing vs Pclass")
print("Chi2 =", chi2, "p-value =", p)

observado = contingency.values
esperado = expected.astype(int)
contingency

pd.DataFrame(esperado, index=contingency.index, columns=contingency.columns)

"""Esto nos lleva a la conclusión de que no es independiente la falta de valores de edad, aún si no es una relación lineal. En específico, la primera y *sobre todo* la segunda clase tienen menos valores faltantes de lo esperado, mientras que la tercera clase tiene bastantes valores faltantes más de lo esperado.

### Matriz de correlación
"""

corr_vars = [
    'Age_missing', 'Pclass', 'SibSp', 'Cabin_missing', 'Embarked_missing',
    'Survived', 'Fare', 'FamilySize', 'Parch'
]

metodo = 'Spearman' # Ningun metodo muestra una fuerte correlación en la matriz
corr_matrix = df[corr_vars].corr(method=metodo.lower())

# Graficar heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", center=0, fmt=".2f")
plt.title(f"Matriz de Correlación ({metodo}) entre variables y valores Faltantes")
plt.show()

"""# Estrategias de Imputación

Para la edad y el puerto de embarcación exploramos 3 métodos de imputación de los datos faltantes. Esto no es posible para la cabina, pues no es una variable ni discreta ni categórica. De la misma manera que no podríamos rellenar nombres que faltaran, no se puede rellenar por medio de estadística el nombre dado a las cabinas, que claramente tienen un sistema para su nombre que desconocemos.
"""

df["Cabin"].dropna().head()

"""### Método simple

Para el puerto de embarcación, la forma más simple de rellenar los dos datos faltantes es la moda del dataset completo, **Southampton**.
"""

df["Embarked"].mode()

"""Para la edad, podemos tomar la mediana, para no dejar que la cola grande a la derecha deforme la representación real de los datos. Esta cola la vimos en la exploración inicial de los datos."""

print("Promedio:", df['Age'].dropna().mean())
print("Mediana:", df['Age'].dropna().median())

"""Realmente son muy similares, pero es más apropiado para la forma de los datos.

### Método basado en grupos

La imputación por grupos nos permite rellenar con valores seleccionados más inteligentemente, basándonos en el demográfico específico que queremos rellenar. Lamentablemente, no es tan sencillo encontrar diferencias significantes segmentando en grupos

Para el puerto en el que se embarca, podemos tomar la moda de cada clase, pero somos conscientes de que al solo faltar dos datos, en la misma clase, esto no hace mucha diferencia.
"""

group = df.groupby("Pclass")["Embarked"]
group.value_counts()